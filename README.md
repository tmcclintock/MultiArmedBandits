# MultiArmedBandits [![Build Status](https://travis-ci.com/tmcclintock/MultiArmedBandits.svg?branch=master)](https://travis-ci.com/tmcclintock/MultiArmedBandits)

An implementation of a few multi-armed bandit algorithms.

Bandit algorithms learn how to balance exploitation with exploration when attempting to maximize rewards obtained from a single-state (but possibly non-stationary) environment. This repository is for building and experimenting with various bandit algorithms.