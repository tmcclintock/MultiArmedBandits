# MultiArmedBandits [![Build Status](https://travis-ci.com/tmcclintock/MultiArmedBandits.svg?branch=master)](https://travis-ci.com/tmcclintock/MultiArmedBandits)[![Coverage Status](https://coveralls.io/repos/github/tmcclintock/MultiArmedBandits/badge.svg?branch=master)](https://coveralls.io/github/tmcclintock/MultiArmedBandits?branch=master)

An implementation of a few multi-armed bandit algorithms.

Bandit algorithms learn how to balance exploitation with exploration when attempting to maximize rewards obtained from a single-state (but possibly non-stationary) environment. This repository is for building and experimenting with various bandit algorithms.